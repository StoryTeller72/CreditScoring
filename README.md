# CreditScoring 
Данный проект посвещен решению задачи предсказания дефолта для ипотечных займов.

Банки получают значительную прибыль от кредитования. Однако это часто сопряжено с риском. Заёмщик может не выполнить свои обязательства по кредиту. Чтобы смягчить эту проблему, банки решили использовать машинное обучение.

Задача состоит в разработке надежной модель машинного обучения для определения вероятности дефолта нового заёмщика.

## Данные
Для обучения был использован  [Loan Default Dataset](https://www.kaggle.com/datasets/yasserh/loan-default-dataset), предоставленный платформой Kaggle.
Набор данных огромен и включает множество детерминированных факторов, таких как доход заёмщика, пол, цель кредита и т. д (описание признаков можно посмотреть в [файле с описание признаков](Data\features.md)). В наборе данных присутствует сильная мультиколлинеарность и пустые значения. Также присуствует существенный дисбаланс классов. 
<div align="center">
   <img src=Images\target_percent.png>
</div>

Больше всего пропусков у признаков dtir1, LTV, propertry_value, Upfront_charges, Interes_rate_spread, rate_of_interest. Для невыплаченных кредитов информация об этих признаках может отсуствовать полностью. 

<div align="center">
   <img src=Images\missedDataByTarget.png>
</div>

Данный график говорит, о том что нужно вернуть к этапу сборки данных, потому что пропущены очень важные признаки. В рамках данного проекта такой возможности нет, поэтому попробуем восстановить эти пропуски.

### Востановление данных.
В силу того, что информация о признаках rate_of_interest, interest_rate_spread, Upfront_charges для не выплаченных кредитов отсутствует был реализован следующий подход:
    
- Предположить что у людей одного возраста примерно одинаковая кредитная нагрузка и зарплата, и восстановить dtir1 и income средним  
- Предположить, что у зданий с одинаковыми параметрами примерно одинаковые стоимости и востановить property_value, а потом уже и LTV
    
- Попробовать восстановить пропуски в interestRate с помощью  BayesianRidge.
    
- Удалить колонки upfront_charges (слабое скоррелированна с целевой переменной),Interest_rate_spread (полностью пустая + сильно скорелирована с interest_rate)

### EDA и гипотезы
В ходе исследования данных были сделаны следующие выводы:
- Оказалось, высокий кредитный рейтинг не гарантирует возврата кредита. 
- Крупные кредиты возвращают чуть чаще
- Люди с высоким доходом, чаще выплачивают кредиты
- Пол заёмщика не влияет на возврат кредита
- Цель кредита не влияет на вероятность возврата кредита
- Частные кредиты возвращают чаще чем коммерческие
- Кредиты которые требуют единовременной оплаты по истичению срока, возвращают гораздо реже
- Заисключением самых молодых и самых взрослых заёмщиков, возраст никак не влияет на возврат кредита.
- Люди у которых низкая кредитная нагрузка (dtir1) заметно чаще возвращают займы.
- Тип кредита влияет на то вернуть его или нет 

## Обучение моделей.
В силу того, что датасет содержит данные о ипотечных кредитах, для банков важно не выдавать кредиты ненадежным заёмщикам. Потому что убытки в таком случае велики. Так же важна не только метка целевой переменной, но и вероятность дефолта. Поэтим причинам будем ориентироваться на метрики **Recall** и **ROC-AUC**.

Также в датасете присутствует сильный дисбаланс классов поэтому для комплексной оценки моделей будем так же использовать дополнительный метрики - **preccision, F1, Gini, AUC-PR**.  

## Результаты моделей. 
В качестве базовой модели (baseline) использовалась простая **логиcтическая регрессия**.

|Название алгоритма/ метрики| ROC-AUC | Gini |AUC-PR |Precision |Recall     | F1 (Default)|
|---------------------------|---------|------|-------|----------|-----------|-------------|
|baseline                   |0.822    |0.645 |0.729  | 0.945    |0.459      |	0.618     |
|logistic_regression	    |0.818	  |0.636 |0.717  |	0.602	|0.615	    |   0.608     |
|Decision Tree              |0.779    |0.559 |0.644  |	0.549	|0.607   	|   0.577     |
|Random_forest	            |0.876	  |0.753 |0.807  | 0.941	|0.561	    |   0.703     |
|lightgbm	                |0.884	  |0.768 |0.817  | 0.692    |0.719  	|   0.705     |
|xgboost	                |0.876    |0.752 |0.806	 |0.855 	|0.623	    |   0.721     |
|catBoost	                |0.880    |0.761 |0.810  |0.697 	|0.708      |	0.703     |

Логистическая регрессия с правильными параметрами и предобработкой признаков показала достаточно сбалансированный и хороший результат. И даже смогла превзойти дерево решений. 
Лучшие результаты показали ансамбли основанные на деревьях. При этом случайный лес выделяется очень высоким показателем preccision и почти худшим recall. То есть модель не гарантирует, что сможет детектировать всех неплательщиков, но если модель нашла неплательщика, то она очень уверена в своих предсказаниях.

Если оценивать комплексно, то лучшие результаты показали бустинги. xgboost выделяется не сбалансированностью результатов (высокий precision, низкий recall). 

Таким образом учитывая специфику задачи лучшая модель - **lightgbm**. В силу того что она быстро работает, показывает сбалансированные и достаточно  точные результаты даже на не сбалансированной выборке. 



### Regression

Логистическая регрессия - один из самых популярных методов для кредитного скоринга. Разберем ее преимущества и недостатки.
Преимущества: 
- Интерпретируемость. Веса модели можно трактовать как важность признаков.
- Вероятностный вывод. 
- Простота и вычислительная эффективность. 

Недостатки:
- Чувствительность к коррелированным признакам. Мультиколлинеарность может сделать оценки коэффициентов нестабильными
- Предполагает, что классы линейно разделимы в пространстве признаков. Плохо справляется со сложными границами принятия решений


Для улучшения результатов регрессии была добавлена регулязация и учёт весов  классов в функции ошибки. Так же для обучения не использовались неинформативные признаки и очень сильно скоррелированный признаки (например loan_amount и property_value, зависят почти линейной. Зачастую размер кредита почти равен стоимость недвижимости для покупки которой он берётся). 
С точки зрения модели логистической регресии самые важные параметры - credit_type_EQUI, 
submission_of_application_to_inst, LTV, Secured_by_land, dtir1. Все параметры кроме submission_of_application (документы были поданы лично или онлайн)ожидаемы. Возможно что этот параметр показывает насколько заёмщик отвественный.

### Decision Tree
Преимущества:
- Главным преимущество Деревье решений является высокая интерпретируемость и прозрачность. Объяснимые решения - можно показать весь путь принятия решения. Это облегчает процесс принятия решения для заказчика.
- Деревья автоматическое определяют важные признаки и игнорируют нерелевантные переменные.
- Работа с нелинейными зависимостями. 
- Гибкость к типам данных. Работает с категориальными признаками (образование, отрасль работы). Не требует масштабирования признаков. Могут обрабатывает пропущенные значения

Недостатки:
-  Высокая склонность к переобучению. Может подстроиться под выборку и выдавать на ней очень высокую точность, но показывать плохие результаты на новых данных.
-  Локально оптимальные решения. 

Для того чтобы избежать переобучения деревья подрезались. С помощью поиска по сетке были подобраны лучшие гиперпараметры. Во время обучения заметил, что модель очень сильно ориентируется на признак rate_of_interesst (процентная ставка). Это вызывает трудности, потому что  
у этого признака полностью отсуствовали значения для невыплаченных кредитов и эти значения были искусственно востановлены. Следовательно этот признак может быть сильно смещен относительно реальных данных. Поэтому было принято решение не использовать этот признак для моделей связанных с деревьями. 

<div align="center">
   <img src=Images\DessicionTree.png>
</div>

### Random Forest
Преимущества:
- Обладает более высокой точностью, чем одно единственное дерево. 
- Засчёт независимости деревьев можно обучать параллельно. 
- Более устойчив к переобучению и шуму в данных.
- Работа с разными типами данных и признаками

Недостатки:
- Сложность интерпретации

С точки зрения Random Forest важные признаки -   LTV, income, dtir1, Credit_Score, loan_purpose,loan_amount,     loan_type, credit_type.
### GradienBoosting
Преимущества:
- Показывает хорошие результаты для табличных данных.
- Гибкая настройка под задачу
- Эффективность на несбалансированных данных 
Недостатки:
- Есть риск переобучиться
- Долго обучать (в силу того что это ансамбль последовательных моделей сложно распараллелить)

В рамках проекта попробовал 3 самых популярных реализации этого алгоритма. 
lightgbm обучился ощутимо быстрее остальных алгоритмов и показал высокие результаты. CatBoost обучался дольше остальных алгоритмов и позволил необрабатывать категориальные признаки. Показал высокие и сбалансированные результат.  xgboost в отличиие от других алгоритмов бустинга показал очень высокий preccision, но при этом его recall значительно ниже других моделе.